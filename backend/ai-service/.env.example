


PORT=8000
GRPC_PORT=50053
DEBUG=true
SERVICE_NAME=ai-service

# CORS
CORS_ORIGINS=["*"]

# AI Configuration
OLLAMA_HOST=http://localhost:11434
DEFAULT_MODEL=llama2
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048

# RAG Configuration
ENABLE_RAG=true
EMBEDDING_MODEL=all-MiniLM-L6-v2
VECTOR_DIMENSION=384

# Redis Configuration
REDIS_URL=redis://localhost:6379
CACHE_TTL=3600

# Elasticsearch Configuration
ELASTICSEARCH_URL=http://localhost:9200
ELASTICSEARCH_INDEX=chat_documents

# Logging
LOG_LEVEL=DEBUG